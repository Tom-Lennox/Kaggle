{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic_20200428",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tom-Lennox/Kaggle/blob/master/titanic_20200428.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7awsi5NqD1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# title\n",
        "# 【result】0.65071"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx5YXYCHJNwU",
        "colab_type": "code",
        "outputId": "2ff5e029-cc05-4b15-d8e9-b4e5f6346ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# kaggle APIセット\n",
        "!pip install kaggle\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "# 「Download 100%.」と表示で成功。\n",
        "\n",
        "# [kaggle.json]を持参する。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# jsonファイルを指定の場所に配置\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "# titanicをダウンロードします。\n",
        "!kaggle competitions download -c titanic\n",
        "\n",
        "# jsonファイルを指定の場所に配置\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "# titanicをダウンロードします。\n",
        "!kaggle competitions download -c titanic\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Download 100%.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "cp: cannot create regular file '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading gender_submission.csv to /content\n",
            "  0% 0.00/3.18k [00:00<?, ?B/s]\n",
            "100% 3.18k/3.18k [00:00<00:00, 2.77MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/59.8k [00:00<?, ?B/s]\n",
            "100% 59.8k/59.8k [00:00<00:00, 61.9MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/28.0k [00:00<?, ?B/s]\n",
            "100% 28.0k/28.0k [00:00<00:00, 28.2MB/s]\n",
            "adc.json  drive  gender_submission.csv\tsample_data  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5W3pHaRPbyM",
        "colab_type": "code",
        "outputId": "c911ff80-f042-4748-a28e-78fd6554a6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        }
      },
      "source": [
        "# ▼ all_data作成\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test_x = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "train_x = train.drop(\"Survived\",axis=1)\n",
        "train_y = train[\"Survived\"]\n",
        "test_x = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "train_x['label'] = 'train'\n",
        "test_x['label'] = 'test'\n",
        "all_data = pd.concat([train_x,test_x],axis=0,sort=False)\n",
        "#学習データとテストデータを統合、カラムsortされると困る。\n",
        "\n",
        "print('▼ 欠損　確認')\n",
        "print(all_data.isnull().sum()[all_data.isnull().sum() > 0].index.tolist())\n",
        "\n",
        "print('▼ 欠損　個数')\n",
        "print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
        "\n",
        "print('▼ 欠損　data')\n",
        "print(all_data['Fare'][all_data['Fare'].isnull() == True])\n",
        "\n",
        "print('▼ 補完')\n",
        "all_data['Age'].fillna(all_data.Age.mean(), inplace=True)\n",
        "all_data['Embarked'] = all_data['Embarked'].fillna(\"None\")\n",
        "all_data['Cabin'] = all_data['Cabin'].fillna(\"None\")\n",
        "all_data['Fare'].fillna(all_data.Fare.mean(), inplace=True)\n",
        "# object, intに分けて自動処理。\n",
        "\n",
        "print('▼ 補完　確認')\n",
        "print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
        "\n",
        "# train['Age'].fillna(train.Age.mean(), inplace=True)\n",
        "all_data[['Age', 'Cabin', 'Embarked', 'Fare']]\n",
        "# ▲ all_data作成"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▼ 欠損　確認\n",
            "['Age', 'Fare', 'Cabin', 'Embarked']\n",
            "▼ 欠損　個数\n",
            "Age          263\n",
            "Fare           1\n",
            "Cabin       1014\n",
            "Embarked       2\n",
            "dtype: int64\n",
            "▼ 欠損　data\n",
            "152   NaN\n",
            "Name: Fare, dtype: float64\n",
            "▼ 補完\n",
            "▼ 補完　確認\n",
            "Series([], dtype: int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.000000</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>29.881138</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>C105</td>\n",
              "      <td>C</td>\n",
              "      <td>108.9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>38.500000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>29.881138</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>29.881138</td>\n",
              "      <td>None</td>\n",
              "      <td>C</td>\n",
              "      <td>22.3583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1309 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Age Cabin Embarked      Fare\n",
              "0    22.000000  None        S    7.2500\n",
              "1    38.000000   C85        C   71.2833\n",
              "2    26.000000  None        S    7.9250\n",
              "3    35.000000  C123        S   53.1000\n",
              "4    35.000000  None        S    8.0500\n",
              "..         ...   ...      ...       ...\n",
              "413  29.881138  None        S    8.0500\n",
              "414  39.000000  C105        C  108.9000\n",
              "415  38.500000  None        S    7.2500\n",
              "416  29.881138  None        S    8.0500\n",
              "417  29.881138  None        C   22.3583\n",
              "\n",
              "[1309 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_jgk4qy0IOO",
        "colab_type": "code",
        "outputId": "ed65e294-435b-469c-f4e7-b4aacb4ef10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "combine1 = [all_data]\n",
        "\n",
        "for all_data in combine1: \n",
        "  all_data['Salutation'] = all_data.Name.str.extract(' ([A-Za-z]+).', expand=False) \n",
        "for all_data in combine1: \n",
        "  all_data['Salutation'] = all_data['Salutation'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "  all_data['Salutation'] = all_data['Salutation'].replace('Mlle', 'Miss')\n",
        "  all_data['Salutation'] = all_data['Salutation'].replace('Ms', 'Miss')\n",
        "  all_data['Salutation'] = all_data['Salutation'].replace('Mme', 'Mrs')\n",
        "Salutation_mapping ={\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \n",
        "for tain in combine1:\n",
        "  all_data['Salutation'] = all_data['Salutation'].map(Salutation_mapping)\n",
        "  all_data['Salutation'] = all_data['Salutation'].fillna(0)\n",
        "  print(all_data['Salutation'].unique())\n",
        "  del all_data['Salutation']\n",
        "  del all_data['Name']\n",
        "\n",
        "# ▲\n",
        "# ▼ Ticket\n",
        "for all_data in combine1:\n",
        "  all_data['ticket_left'] = all_data['Ticket'].apply(lambda x: str(x)[0])\n",
        "  # strに変換 + 1文字目を取得\n",
        "  all_data['ticket_left'] = all_data['ticket_left'].apply(lambda x: str(x))\n",
        "  all_data['del_ticket_left_zero'] = np.where((all_data['ticket_left']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0')\n",
        "  all_data['ticket_left'] = np.where((all_data['ticket_left']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), all_data['ticket_left'], all_data['del_ticket_left_zero'])\n",
        "  del all_data['del_ticket_left_zero']\n",
        "  all_data['tcker_len'] = all_data['Ticket'].apply(lambda x: len(x))\n",
        "  del all_data['Ticket']\n",
        "all_data['ticket_left']=all_data['ticket_left'].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3)\n",
        "print('▼ print(all_data[\"ticket_left\"])')\n",
        "print(all_data['ticket_left'].unique())\n",
        "# ▲ Ticket\n",
        "# ▼ Cabin\n",
        "for all_data in combine1:\n",
        "  all_data['cabin_left'] = all_data['Cabin'].apply(lambda x: str(x)[0])\n",
        "  all_data['cabin_left'] = all_data['cabin_left'].apply(lambda x: str(x))\n",
        "  # print(all_data['cabin_left'].unique())\n",
        "  # ▲ コピペ用\n",
        "  all_data['del_cabin_left_zero'] = np.where((all_data['cabin_left']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']), '0','0')\n",
        "  # ▲ ！手直しの必要有。\n",
        "  all_data['cabin_left'] = np.where((all_data['cabin_left']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']), all_data['cabin_left'], all_data['del_cabin_left_zero'])\n",
        "  # del all_data['Cabin']\n",
        "  del all_data['del_cabin_left_zero']\n",
        "  del all_data['Cabin']\n",
        "all_data['cabin_left']=all_data['cabin_left'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\n",
        "# ▲ ！手直しの必要有。\n",
        "# ▲ Cabin\n",
        "# ▼ family_of　（新規追加）\n",
        "all_data['family_of'] = all_data['SibSp'] + all_data['Parch'] + 1\n",
        "for all_data in combine1:\n",
        "  all_data['is_alone'] = 0\n",
        "  all_data.loc[all_data['family_of'] == 1, 'is_alone'] = 1\n",
        "# ▲ family_of　（新規追加）\n",
        "# ▼ train\n",
        "del all_data['Embarked']\n",
        "del all_data['Sex']\n",
        "#カテゴリ変数となっているカラムを取り出す\n",
        "# cal_list = all_data.dtypes[all_data.dtypes==\"object\"].index.tolist()\n",
        "\n",
        "#カテゴリ変数をget_dummiesによるone-hot-encodingを行う\n",
        "# all_data = pd.get_dummies(all_data,columns=cal_list)\n",
        "\n",
        "# train_x = all_data.iloc[:train_x.shape[0],:].reset_index(drop=True)\n",
        "# test_x = all_data.iloc[train_x.shape[0]:,:].reset_index(drop=True)\n",
        "\n",
        "# Split your data\n",
        "train_x = all_data[all_data['label'] == 'train']\n",
        "test_x = all_data[all_data['label'] == 'test']\n",
        "\n",
        "# Drop your labels\n",
        "train_x = train_x.drop('label', axis=1)\n",
        "test_x = test_x.drop('label', axis=1)\n",
        "# 分割\n",
        "\n",
        "print(\"train_x: \"+str(train_x.shape))\n",
        "print(\"test_x: \"+str(test_x.shape))\n",
        "#サイズを確認\n",
        "\n",
        "print(train_x.isnull().sum()[train_x.isnull().sum() > 0])\n",
        "print(test_x.isnull().sum()[test_x.isnull().sum() > 0])\n",
        "# ▲ "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 3. 2. 4. 0. 5.]\n",
            "▼ print(all_data[\"ticket_left\"])\n",
            "[3 0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVjPvhKHdSES",
        "colab_type": "code",
        "outputId": "62467711-5e9e-4cff-8125-470bac529b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "print('▼ train')\n",
        "train_x.info()\n",
        "print('▼ test')\n",
        "test_x.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▼ train\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 891 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Pclass       891 non-null    int64  \n",
            " 2   Age          891 non-null    float64\n",
            " 3   SibSp        891 non-null    int64  \n",
            " 4   Parch        891 non-null    int64  \n",
            " 5   Fare         891 non-null    float64\n",
            " 6   ticket_left  891 non-null    int64  \n",
            " 7   tcker_len    891 non-null    int64  \n",
            " 8   cabin_left   891 non-null    int64  \n",
            " 9   family_of    891 non-null    int64  \n",
            " 10  is_alone     891 non-null    int64  \n",
            "dtypes: float64(2), int64(9)\n",
            "memory usage: 83.5 KB\n",
            "▼ test\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Age          418 non-null    float64\n",
            " 3   SibSp        418 non-null    int64  \n",
            " 4   Parch        418 non-null    int64  \n",
            " 5   Fare         418 non-null    float64\n",
            " 6   ticket_left  418 non-null    int64  \n",
            " 7   tcker_len    418 non-null    int64  \n",
            " 8   cabin_left   418 non-null    int64  \n",
            " 9   family_of    418 non-null    int64  \n",
            " 10  is_alone     418 non-null    int64  \n",
            "dtypes: float64(2), int64(9)\n",
            "memory usage: 39.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuVostu69iDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = svm.SVC()\n",
        "clf.fit(train_x,train_y)\n",
        "prediction = clf.predict(test_x)\n",
        "\n",
        "#ランダムフォレストによる分類\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(train_x, train_y)\n",
        "prediction = random_forest.predict(test_x)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "  \"PassengerId\": test_x[\"PassengerId\"],\n",
        "  \"Survived\": prediction\n",
        "})\n",
        "submission.to_csv('result.csv', index=False)     \n",
        "files.download('result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}