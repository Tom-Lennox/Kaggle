{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic_20200410 のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tom-Lennox/Kaggle/blob/master/titanic_20200410_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7awsi5NqD1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx5YXYCHJNwU",
        "colab_type": "code",
        "outputId": "9a74d999-10b3-4147-f5d3-a17a9eebb290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# kaggle APIセット\n",
        "!pip install kaggle\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "# 「Download 100%.」と表示で成功。\n",
        "\n",
        "# [kaggle.json]を持参する。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# jsonファイルを指定の場所に配置\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "# titanicをダウンロードします。\n",
        "!kaggle competitions download -c titanic\n",
        "\n",
        "# jsonファイルを指定の場所に配置\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "# titanicをダウンロードします。\n",
        "!kaggle competitions download -c titanic\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Download 100%.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "cp: cannot create regular file '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/28.0k [00:00<?, ?B/s]\n",
            "100% 28.0k/28.0k [00:00<00:00, 48.9MB/s]\n",
            "Downloading gender_submission.csv to /content\n",
            "  0% 0.00/3.18k [00:00<?, ?B/s]\n",
            "100% 3.18k/3.18k [00:00<00:00, 3.28MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/59.8k [00:00<?, ?B/s]\n",
            "100% 59.8k/59.8k [00:00<00:00, 53.0MB/s]\n",
            "adc.json  drive  gender_submission.csv\tsample_data  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Ck1HykqmIz",
        "colab_type": "code",
        "outputId": "9023f13a-0cf1-402a-9ca4-b41d2499e57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# RandomForestClassifier\n",
        "# 複数の決定木を使って各決定木の予測結果の多数決で結果を求める方法\n",
        "# ｜Decision Tree(決定木\n",
        "# 　｜Classification Tree 分類木\n",
        "# 　｜Regression Tree 回帰木\n",
        "\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "# とりあえずファイルを読み込む\n",
        "\n",
        "# train.head()\n",
        "# 名前確かに敬称あるね。\n",
        "# ticketはアルファベットがヒントになりそう。\n",
        "# Name: 敬称を別カラムに移植、削除\n",
        "# objectで抽出したものをone-hot-encordingで置換（手動置換は無駄。\n",
        "# ticket ⇒ 条件でカラム作成して代入 ⇒ \n",
        "\n",
        "print('▼　inull list')\n",
        "print(train.isnull().sum()[train.isnull().sum() > 0].index.tolist())\n",
        "# null抽出\n",
        "\n",
        "print('▼　Embarked fillna')\n",
        "# Embarked　処理：\n",
        "# １．noneで置き換えてohe\n",
        "# ２．mean()\n",
        "train.head()\n",
        "train['Embarked'] = train['Embarked'].fillna(\"None\")\n",
        "print(train['Embarked'].unique())\n",
        "\n",
        "print('▼ Ticket')\n",
        "train.head()\n",
        "print(train['Ticket'].unique().tolist())\n",
        "\n",
        "print('▼ Cabin')\n",
        "train['Cabin'] = train['Cabin'].fillna(\"None\")\n",
        "print(train['Cabin'].isnull().sum())\n",
        "# 【統合先】"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▼　inull list\n",
            "['Age', 'Cabin', 'Embarked']\n",
            "▼　Embarked fillna\n",
            "['S' 'C' 'Q' 'None']\n",
            "▼ Ticket\n",
            "['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450', '330877', '17463', '349909', '347742', '237736', 'PP 9549', '113783', 'A/5. 2151', '347082', '350406', '248706', '382652', '244373', '345763', '2649', '239865', '248698', '330923', '113788', '347077', '2631', '19950', '330959', '349216', 'PC 17601', 'PC 17569', '335677', 'C.A. 24579', 'PC 17604', '113789', '2677', 'A./5. 2152', '345764', '2651', '7546', '11668', '349253', 'SC/Paris 2123', '330958', 'S.C./A.4. 23567', '370371', '14311', '2662', '349237', '3101295', 'A/4. 39886', 'PC 17572', '2926', '113509', '19947', 'C.A. 31026', '2697', 'C.A. 34651', 'CA 2144', '2669', '113572', '36973', '347088', 'PC 17605', '2661', 'C.A. 29395', 'S.P. 3464', '3101281', '315151', 'C.A. 33111', 'S.O.C. 14879', '2680', '1601', '348123', '349208', '374746', '248738', '364516', '345767', '345779', '330932', '113059', 'SO/C 14885', '3101278', 'W./C. 6608', 'SOTON/OQ 392086', '343275', '343276', '347466', 'W.E.P. 5734', 'C.A. 2315', '364500', '374910', 'PC 17754', 'PC 17759', '231919', '244367', '349245', '349215', '35281', '7540', '3101276', '349207', '343120', '312991', '349249', '371110', '110465', '2665', '324669', '4136', '2627', 'STON/O 2. 3101294', '370369', 'PC 17558', 'A4. 54510', '27267', '370372', 'C 17369', '2668', '347061', '349241', 'SOTON/O.Q. 3101307', 'A/5. 3337', '228414', 'C.A. 29178', 'SC/PARIS 2133', '11752', '7534', 'PC 17593', '2678', '347081', 'STON/O2. 3101279', '365222', '231945', 'C.A. 33112', '350043', '230080', '244310', 'S.O.P. 1166', '113776', 'A.5. 11206', 'A/5. 851', 'Fa 265302', 'PC 17597', '35851', 'SOTON/OQ 392090', '315037', 'CA. 2343', '371362', 'C.A. 33595', '347068', '315093', '363291', '113505', 'PC 17318', '111240', 'STON/O 2. 3101280', '17764', '350404', '4133', 'PC 17595', '250653', 'LINE', 'SC/PARIS 2131', '230136', '315153', '113767', '370365', '111428', '364849', '349247', '234604', '28424', '350046', 'PC 17610', '368703', '4579', '370370', '248747', '345770', '3101264', '2628', 'A/5 3540', '347054', '2699', '367231', '112277', 'SOTON/O.Q. 3101311', 'F.C.C. 13528', 'A/5 21174', '250646', '367229', '35273', 'STON/O2. 3101283', '243847', '11813', 'W/C 14208', 'SOTON/OQ 392089', '220367', '21440', '349234', '19943', 'PP 4348', 'SW/PP 751', 'A/5 21173', '236171', '347067', '237442', 'C.A. 29566', 'W./C. 6609', '26707', 'C.A. 31921', '28665', 'SCO/W 1585', '367230', 'W./C. 14263', 'STON/O 2. 3101275', '2694', '19928', '347071', '250649', '11751', '244252', '362316', '113514', 'A/5. 3336', '370129', '2650', 'PC 17585', '110152', 'PC 17755', '230433', '384461', '110413', '112059', '382649', 'C.A. 17248', '347083', 'PC 17582', 'PC 17760', '113798', '250644', 'PC 17596', '370375', '13502', '347073', '239853', 'C.A. 2673', '336439', '347464', '345778', 'A/5. 10482', '113056', '349239', '345774', '349206', '237798', '370373', '19877', '11967', 'SC/Paris 2163', '349236', '349233', 'PC 17612', '2693', '113781', '19988', '9234', '367226', '226593', 'A/5 2466', '17421', 'PC 17758', 'P/PP 3381', 'PC 17485', '11767', 'PC 17608', '250651', '349243', 'F.C.C. 13529', '347470', '29011', '36928', '16966', 'A/5 21172', '349219', '234818', '345364', '28551', '111361', '113043', 'PC 17611', '349225', '7598', '113784', '248740', '244361', '229236', '248733', '31418', '386525', 'C.A. 37671', '315088', '7267', '113510', '2695', '2647', '345783', '237671', '330931', '330980', 'SC/PARIS 2167', '2691', 'SOTON/O.Q. 3101310', 'C 7076', '110813', '2626', '14313', 'PC 17477', '11765', '3101267', '323951', 'C 7077', '113503', '2648', '347069', 'PC 17757', '2653', 'STON/O 2. 3101293', '349227', '27849', '367655', 'SC 1748', '113760', '350034', '3101277', '350052', '350407', '28403', '244278', '240929', 'STON/O 2. 3101289', '341826', '4137', '315096', '28664', '347064', '29106', '312992', '349222', '394140', 'STON/O 2. 3101269', '343095', '28220', '250652', '28228', '345773', '349254', 'A/5. 13032', '315082', '347080', 'A/4. 34244', '2003', '250655', '364851', 'SOTON/O.Q. 392078', '110564', '376564', 'SC/AH 3085', 'STON/O 2. 3101274', '13507', 'C.A. 18723', '345769', '347076', '230434', '65306', '33638', '113794', '2666', '113786', '65303', '113051', '17453', 'A/5 2817', '349240', '13509', '17464', 'F.C.C. 13531', '371060', '19952', '364506', '111320', '234360', 'A/S 2816', 'SOTON/O.Q. 3101306', '113792', '36209', '323592', '315089', 'SC/AH Basle 541', '7553', '31027', '3460', '350060', '3101298', '239854', 'A/5 3594', '4134', '11771', 'A.5. 18509', '65304', 'SOTON/OQ 3101317', '113787', 'PC 17609', 'A/4 45380', '36947', 'C.A. 6212', '350035', '315086', '364846', '330909', '4135', '26360', '111427', 'C 4001', '382651', 'SOTON/OQ 3101316', 'PC 17473', 'PC 17603', '349209', '36967', 'C.A. 34260', '226875', '349242', '12749', '349252', '2624', '2700', '367232', 'W./C. 14258', 'PC 17483', '3101296', '29104', '2641', '2690', '315084', '113050', 'PC 17761', '364498', '13568', 'WE/P 5735', '2908', '693', 'SC/PARIS 2146', '244358', '330979', '2620', '347085', '113807', '11755', '345572', '372622', '349251', '218629', 'SOTON/OQ 392082', 'SOTON/O.Q. 392087', 'A/4 48871', '349205', '2686', '350417', 'S.W./PP 752', '11769', 'PC 17474', '14312', 'A/4. 20589', '358585', '243880', '2689', 'STON/O 2. 3101286', '237789', '13049', '3411', '237565', '13567', '14973', 'A./5. 3235', 'STON/O 2. 3101273', 'A/5 3902', '364848', 'SC/AH 29037', '248727', '2664', '349214', '113796', '364511', '111426', '349910', '349246', '113804', 'SOTON/O.Q. 3101305', '370377', '364512', '220845', '31028', '2659', '11753', '350029', '54636', '36963', '219533', '349224', '334912', '27042', '347743', '13214', '112052', '237668', 'STON/O 2. 3101292', '350050', '349231', '13213', 'S.O./P.P. 751', 'CA. 2314', '349221', '8475', '330919', '365226', '349223', '29751', '2623', '5727', '349210', 'STON/O 2. 3101285', '234686', '312993', 'A/5 3536', '19996', '29750', 'F.C. 12750', 'C.A. 24580', '244270', '239856', '349912', '342826', '4138', '330935', '6563', '349228', '350036', '24160', '17474', '349256', '2672', '113800', '248731', '363592', '35852', '348121', 'PC 17475', '36864', '350025', '223596', 'PC 17476', 'PC 17482', '113028', '7545', '250647', '348124', '34218', '36568', '347062', '350048', '12233', '250643', '113806', '315094', '36866', '236853', 'STON/O2. 3101271', '239855', '28425', '233639', '349201', '349218', '16988', '376566', 'STON/O 2. 3101288', '250648', '113773', '335097', '29103', '392096', '345780', '349204', '350042', '29108', '363294', 'SOTON/O2 3101272', '2663', '347074', '112379', '364850', '8471', '345781', '350047', 'S.O./P.P. 3', '2674', '29105', '347078', '383121', '36865', '2687', '113501', 'W./C. 6607', 'SOTON/O.Q. 3101312', '374887', '3101265', '12460', 'PC 17600', '349203', '28213', '17465', '349244', '2685', '2625', '347089', '347063', '112050', '347087', '248723', '3474', '28206', '364499', '112058', 'STON/O2. 3101290', 'S.C./PARIS 2079', 'C 7075', '315098', '19972', '368323', '367228', '2671', '347468', '2223', 'PC 17756', '315097', '392092', '11774', 'SOTON/O2 3101287', '2683', '315090', 'C.A. 5547', '349213', '347060', 'PC 17592', '392091', '113055', '2629', '350026', '28134', '17466', '233866', '236852', 'SC/PARIS 2149', 'PC 17590', '345777', '349248', '695', '345765', '2667', '349212', '349217', '349257', '7552', 'C.A./SOTON 34068', 'SOTON/OQ 392076', '211536', '112053', '111369', '370376']\n",
            "▼ Cabin\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5W3pHaRPbyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "e1090468-dd91-438a-ea60-96b6db3c44b1"
      },
      "source": [
        "# ▼ all_data作成\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test_x = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "train_x = train.drop(\"Survived\",axis=1)\n",
        "train_y = train[\"Survived\"]\n",
        "test_x = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "all_data = pd.concat([train_x,test_x],axis=0,sort=False)\n",
        "#学習データとテストデータを統合、カラムsortされると困る。\n",
        "\n",
        "print('▼ 欠損　確認')\n",
        "print(all_data.isnull().sum()[all_data.isnull().sum() > 0].index.tolist())\n",
        "\n",
        "print('▼ 欠損　個数')\n",
        "print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
        "\n",
        "print('▼ 欠損　data')\n",
        "print(all_data['Fare'][all_data['Fare'].isnull() == True])\n",
        "\n",
        "print('▼ 補完')\n",
        "all_data['Age'].fillna(all_data.Age.mean(), inplace=True)\n",
        "all_data['Embarked'] = all_data['Embarked'].fillna(\"None\")\n",
        "all_data['Cabin'] = all_data['Cabin'].fillna(\"None\")\n",
        "all_data['Fare'].fillna(all_data.Fare.mean(), inplace=True)\n",
        "# object, intに分けて自動処理。\n",
        "\n",
        "print('▼ 補完　確認')\n",
        "print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
        "\n",
        "# train['Age'].fillna(train.Age.mean(), inplace=True)\n",
        "all_data[['Age', 'Cabin', 'Embarked', 'Fare']]\n",
        "# ▲ all_data作成"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▼ 欠損　確認\n",
            "['Age', 'Fare', 'Cabin', 'Embarked']\n",
            "▼ 欠損　個数\n",
            "Age          263\n",
            "Fare           1\n",
            "Cabin       1014\n",
            "Embarked       2\n",
            "dtype: int64\n",
            "▼ 欠損　data\n",
            "152   NaN\n",
            "Name: Fare, dtype: float64\n",
            "▼ 補完\n",
            "▼ 補完　確認\n",
            "Series([], dtype: int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.000000</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>29.881138</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>C105</td>\n",
              "      <td>C</td>\n",
              "      <td>108.9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>38.500000</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>29.881138</td>\n",
              "      <td>None</td>\n",
              "      <td>S</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>29.881138</td>\n",
              "      <td>None</td>\n",
              "      <td>C</td>\n",
              "      <td>22.3583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1309 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Age Cabin Embarked      Fare\n",
              "0    22.000000  None        S    7.2500\n",
              "1    38.000000   C85        C   71.2833\n",
              "2    26.000000  None        S    7.9250\n",
              "3    35.000000  C123        S   53.1000\n",
              "4    35.000000  None        S    8.0500\n",
              "..         ...   ...      ...       ...\n",
              "413  29.881138  None        S    8.0500\n",
              "414  39.000000  C105        C  108.9000\n",
              "415  38.500000  None        S    7.2500\n",
              "416  29.881138  None        S    8.0500\n",
              "417  29.881138  None        C   22.3583\n",
              "\n",
              "[1309 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_jgk4qy0IOO",
        "colab_type": "code",
        "outputId": "c38f94d4-ef4b-4477-d8df-5c36355d3b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "combine1 = [all_data]\n",
        "\n",
        "for all_data in combine1: \n",
        "  all_data['Salutation'] = all_data.Name.str.extract(' ([A-Za-z]+).', expand=False) \n",
        "for all_data in combine1: \n",
        "  all_data['Salutation'] = all_data['Salutation'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "  all_data['Salutation'] = all_data['Salutation'].replace('Mlle', 'Miss')\n",
        "  all_data['Salutation'] = all_data['Salutation'].replace('Ms', 'Miss')\n",
        "  all_data['Salutation'] = all_data['Salutation'].replace('Mme', 'Mrs')\n",
        "Salutation_mapping ={\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \n",
        "for tain in combine1:\n",
        "  all_data['Salutation'] = all_data['Salutation'].map(Salutation_mapping)\n",
        "  all_data['Salutation'] = all_data['Salutation'].fillna(0)\n",
        "  print(all_data['Salutation'].unique())\n",
        "  del all_data['Salutation']\n",
        "  del all_data['Name']\n",
        "\n",
        "# ▲\n",
        "# ▼ Ticket\n",
        "for all_data in combine1:\n",
        "  all_data['ticket_left'] = all_data['Ticket'].apply(lambda x: str(x)[0])\n",
        "  # strに変換 + 1文字目を取得\n",
        "  all_data['ticket_left'] = all_data['ticket_left'].apply(lambda x: str(x))\n",
        "  all_data['del_ticket_left_zero'] = np.where((all_data['ticket_left']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0')\n",
        "  all_data['ticket_left'] = np.where((all_data['ticket_left']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), all_data['ticket_left'], all_data['del_ticket_left_zero'])\n",
        "  del all_data['del_ticket_left_zero']\n",
        "  all_data['tcker_len'] = all_data['Ticket'].apply(lambda x: len(x))\n",
        "  del all_data['Ticket']\n",
        "all_data['ticket_left']=all_data['ticket_left'].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3)\n",
        "print('▼ print(all_data[\"ticket_left\"])')\n",
        "print(all_data['ticket_left'].unique())\n",
        "# ▲ Ticket\n",
        "# ▼ Cabin\n",
        "for all_data in combine1:\n",
        "  all_data['cabin_left'] = all_data['Cabin'].apply(lambda x: str(x)[0])\n",
        "  all_data['cabin_left'] = all_data['cabin_left'].apply(lambda x: str(x))\n",
        "  # print(all_data['cabin_left'].unique())\n",
        "  # ▲ コピペ用\n",
        "  all_data['del_cabin_left_zero'] = np.where((all_data['cabin_left']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']), '0','0')\n",
        "  # ▲ ！手直しの必要有。\n",
        "  all_data['cabin_left'] = np.where((all_data['cabin_left']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']), all_data['cabin_left'], all_data['del_cabin_left_zero'])\n",
        "  # del all_data['Cabin']\n",
        "  del all_data['del_cabin_left_zero']\n",
        "  del all_data['Cabin']\n",
        "all_data['cabin_left']=all_data['cabin_left'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\n",
        "# ▲ ！手直しの必要有。\n",
        "# ▲ Cabin\n",
        "# ▼ family_of　（新規追加）\n",
        "all_data['family_of'] = all_data['SibSp'] + all_data['Parch'] + 1\n",
        "for all_data in combine1:\n",
        "  all_data['is_alone'] = 0\n",
        "  all_data.loc[all_data['family_of'] == 1, 'is_alone'] = 1\n",
        "# ▲ family_of　（新規追加）"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 3. 2. 4. 0. 5.]\n",
            "▼ print(all_data[\"ticket_left\"])\n",
            "[3 0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrg512bAEyTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "045b6043-6548-4faf-e92d-9a8fe3787678"
      },
      "source": [
        "# print(all_data['Embarked'].unique())\n",
        "# all_data.info()\n",
        "# print(all_data.dtypes[all_data.dtypes==\"object\"].index.tolist())\n",
        "# cal_list = all_data.dtypes[all_data.dtypes==\"object\"].index.tolist()\n",
        "# print(cal_list)\n",
        "# all_data.info()\n",
        "# test_x.info()\n",
        "\n",
        "all_data.info()\n",
        "all_data\n",
        "\n",
        "Embark_dum  = pd.get_dummies(all_data['Embarked'])\n",
        "Embark_dum.columns = ['Class1','Class2','Class3', 'Class4']\n",
        "Sex_dum = pd.get_dummies(all_data['Sex'])\n",
        "Sex_dum.columns = ['Sex1','Sex2']\n",
        "all_data = all_data.join(Embark_dum)\n",
        "all_data = all_data.join(Sex_dum)\n",
        "\n",
        "del all_data['Embarked']\n",
        "del all_data['Sex']"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 13 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  1309 non-null   int64  \n",
            " 1   Pclass       1309 non-null   int64  \n",
            " 2   Sex          1309 non-null   object \n",
            " 3   Age          1309 non-null   float64\n",
            " 4   SibSp        1309 non-null   int64  \n",
            " 5   Parch        1309 non-null   int64  \n",
            " 6   Fare         1309 non-null   float64\n",
            " 7   Embarked     1309 non-null   object \n",
            " 8   ticket_left  1309 non-null   int64  \n",
            " 9   tcker_len    1309 non-null   int64  \n",
            " 10  cabin_left   1309 non-null   int64  \n",
            " 11  family_of    1309 non-null   int64  \n",
            " 12  is_alone     1309 non-null   int64  \n",
            "dtypes: float64(2), int64(9), object(2)\n",
            "memory usage: 143.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5qBT6Vc_qrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "5839b44c-a735-482d-e49d-2d1c3f7fb514"
      },
      "source": [
        "test_x"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>ticket_left</th>\n",
              "      <th>tcker_len</th>\n",
              "      <th>cabin_left</th>\n",
              "      <th>family_of</th>\n",
              "      <th>is_alone</th>\n",
              "      <th>Class1</th>\n",
              "      <th>Class2</th>\n",
              "      <th>Class3</th>\n",
              "      <th>Class4</th>\n",
              "      <th>Sex1</th>\n",
              "      <th>Sex2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "      <td>3</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14.4542</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003</td>\n",
              "      <td>3</td>\n",
              "      <td>29.881138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7792</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>3</td>\n",
              "      <td>29.881138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7792</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1003</td>\n",
              "      <td>3</td>\n",
              "      <td>29.881138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7792</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1003</td>\n",
              "      <td>3</td>\n",
              "      <td>29.881138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7792</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2921</th>\n",
              "      <td>887</td>\n",
              "      <td>2</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2922</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2923</th>\n",
              "      <td>889</td>\n",
              "      <td>3</td>\n",
              "      <td>29.881138</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2924</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2925</th>\n",
              "      <td>891</td>\n",
              "      <td>3</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2926 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      PassengerId  Pclass        Age  SibSp  ...  Class3  Class4  Sex1  Sex2\n",
              "0             112       3  14.500000      1  ...       1       0     1     0\n",
              "1            1003       3  29.881138      0  ...       0       0     1     0\n",
              "2            1003       3  29.881138      0  ...       0       0     1     0\n",
              "3            1003       3  29.881138      0  ...       1       0     1     0\n",
              "4            1003       3  29.881138      0  ...       1       0     1     0\n",
              "...           ...     ...        ...    ...  ...     ...     ...   ...   ...\n",
              "2921          887       2  27.000000      0  ...       0       1     0     1\n",
              "2922          888       1  19.000000      0  ...       0       1     1     0\n",
              "2923          889       3  29.881138      1  ...       0       1     1     0\n",
              "2924          890       1  26.000000      0  ...       0       0     0     1\n",
              "2925          891       3  32.000000      0  ...       1       0     0     1\n",
              "\n",
              "[2926 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5PJXCqck36M",
        "colab_type": "code",
        "outputId": "54148d11-9660-49df-999e-de62b6c02384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# ▼ train\n",
        "#カテゴリ変数となっているカラムを取り出す\n",
        "cal_list = all_data.dtypes[all_data.dtypes==\"object\"].index.tolist()\n",
        "\n",
        "#カテゴリ変数をget_dummiesによるone-hot-encodingを行う\n",
        "# all_data = pd.get_dummies(all_data,columns=cal_list)\n",
        "\n",
        "train_x = all_data.iloc[:train_x.shape[0],:].reset_index(drop=True)\n",
        "test_x = all_data.iloc[train_x.shape[0]:,:].reset_index(drop=True)\n",
        "# 分割\n",
        "\n",
        "print(\"train_x: \"+str(train_x.shape))\n",
        "print(\"test_x: \"+str(test_x.shape))\n",
        "#サイズを確認\n",
        "\n",
        "print(train_x.isnull().sum()[train_x.isnull().sum() > 0])\n",
        "print(test_x.isnull().sum()[test_x.isnull().sum() > 0])\n",
        "\n",
        "train_data = train_x.values\n",
        "xs = train_data[:, 2:]\n",
        "# Pclass以降の変数\n",
        "y  = train_y\n",
        "# 正解データ\n",
        "\n",
        "test_data = test_x.values\n",
        "xs_test = test_data[:, 1:]\n",
        "# ▲ "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x: (891, 17)\n",
            "test_x: (2926, 17)\n",
            "Series([], dtype: int64)\n",
            "Series([], dtype: int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVjPvhKHdSES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "ad83e252-1e70-4901-ca15-4e86baf790eb"
      },
      "source": [
        "# all_data.info()\n",
        "# all_data\n",
        "# xs\n",
        "print('▼ train')\n",
        "train_x.info()\n",
        "print('▼ test')\n",
        "test_x.info()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▼ train\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 17 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Pclass       891 non-null    int64  \n",
            " 2   Age          891 non-null    float64\n",
            " 3   SibSp        891 non-null    int64  \n",
            " 4   Parch        891 non-null    int64  \n",
            " 5   Fare         891 non-null    float64\n",
            " 6   ticket_left  891 non-null    int64  \n",
            " 7   tcker_len    891 non-null    int64  \n",
            " 8   cabin_left   891 non-null    int64  \n",
            " 9   family_of    891 non-null    int64  \n",
            " 10  is_alone     891 non-null    int64  \n",
            " 11  Class1       891 non-null    uint8  \n",
            " 12  Class2       891 non-null    uint8  \n",
            " 13  Class3       891 non-null    uint8  \n",
            " 14  Class4       891 non-null    uint8  \n",
            " 15  Sex1         891 non-null    uint8  \n",
            " 16  Sex2         891 non-null    uint8  \n",
            "dtypes: float64(2), int64(9), uint8(6)\n",
            "memory usage: 81.9 KB\n",
            "▼ test\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2926 entries, 0 to 2925\n",
            "Data columns (total 17 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  2926 non-null   int64  \n",
            " 1   Pclass       2926 non-null   int64  \n",
            " 2   Age          2926 non-null   float64\n",
            " 3   SibSp        2926 non-null   int64  \n",
            " 4   Parch        2926 non-null   int64  \n",
            " 5   Fare         2926 non-null   float64\n",
            " 6   ticket_left  2926 non-null   int64  \n",
            " 7   tcker_len    2926 non-null   int64  \n",
            " 8   cabin_left   2926 non-null   int64  \n",
            " 9   family_of    2926 non-null   int64  \n",
            " 10  is_alone     2926 non-null   int64  \n",
            " 11  Class1       2926 non-null   uint8  \n",
            " 12  Class2       2926 non-null   uint8  \n",
            " 13  Class3       2926 non-null   uint8  \n",
            " 14  Class4       2926 non-null   uint8  \n",
            " 15  Sex1         2926 non-null   uint8  \n",
            " 16  Sex2         2926 non-null   uint8  \n",
            "dtypes: float64(2), int64(9), uint8(6)\n",
            "memory usage: 268.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuVostu69iDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "256cc282-a8ee-4b3b-b6c4-473f5d928eed"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest=RandomForestClassifier()\n",
        "random_forest.fit(xs, y)\n",
        "Y_pred = random_forest.predict(xs_test)\n",
        "\n",
        "# import csv\n",
        "# with open(\"predict_result_data.csv\", \"w\") as f:\n",
        "#     writer = csv.writer(f, lineterminator='\\n')\n",
        "#     writer.writerow([\"PassengerId\", \"Survived\"])\n",
        "#     for pid, survived in zip(test_data[:,0].astype(int), Y_pred.astype(int)):\n",
        "#         writer.writerow([pid, survived])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0f8ee3579002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 15 and input n_features is 16 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o922KikUEEYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ▽ 以下、\n",
        "train_data = train.values\n",
        "xs = train_data[:, 2:] # Pclass以降の変数\n",
        "y  = train_data[:, 1]  # 正解データ\n",
        "# △ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL059cDEvIJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# ▼ohe関連\n",
        "# # 追記\n",
        "# # ▼\n",
        "# # 処理のために結合\n",
        "# train_x = pd.read_csv(\"/content/train.csv\")\n",
        "# test_x = pd.read_csv(\"/content/test.csv\")\n",
        "# print('train_x: ' + str(train_x.shape))\n",
        "# print('test_x: '  + str(test_x.shape))\n",
        "# # sort: カラム名のsort。\n",
        "# all_data = pd.concat([train_x,test_x],axis=0,sort=True)\n",
        "# print('all_data: '  + str(all_data.shape))\n",
        "# # ▲\n",
        "# # ▼\n",
        "# # # 学習データとテストデータに再分割\n",
        "# # [tips]shape使え。\n",
        "# # train_x = all_data.iloc[:train_x.shape[0],:].reset_index(drop=True)\n",
        "# # test_x = all_data.iloc[train_x.shape[0]:,:].reset_index(drop=True)\n",
        "# # ▲\n",
        "# # ▼\n",
        "# # nullは下記で取得できる。\n",
        "# print('▼train_x')\n",
        "# print(train_x.isnull().sum())\n",
        "# print('▼test_x')\n",
        "# print(test_x.isnull().sum())\n",
        "# print(train[['Age','Cabin','Embarked']])\n",
        "# all_data.head(3)\n",
        "# # ▲\n",
        "# # ▼\n",
        "# # pandas, one-hot-encodingを行う。\n",
        "# one-hot-encoding\n",
        "# cal_list = all_data.dtypes[all_data.dtypes==\"object\"].index.tolist()\n",
        "# all_data = pd.get_dummies(all_data,columns=cal_list)\n",
        "# all_data\n",
        "# # ▲"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}